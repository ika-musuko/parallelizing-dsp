Parallelizing Digital Signal Processing

Abstract
---------
    Classical computing systems are sequential in nature, whether it be hardware or software; that is each task is instructed in sequence, one at a time. This is due to when we construct and describe algorithms or formulas, we often think of them in this sequential fashion. However, we as we reach the end of Moore's Law, individual computing units themselves are reaching their maximum potential. The obvious solution to this is run multiple computing units in parallel to accomplish tasks. This is how the field of parallel processing was birthed. However, with this solution arises a whole new field of problems, that is, sequential algorithms must be properly restructured to work in a parallel environment.
    One large field which has obvious benefits from utilizing parallel processing is digital signal processing. Digital signal processing is simply, taking a stream of data, performing some operations on the data, and outputting the modified data stream. Digital signal processing algorithms are computationally expensive, however they are inherently suited to task partitioning, a key indicator of whether something is parallelizable. If DSP algorithms are parallelized, this can reduce individual CPU load while getting the same results as normal sequential algorithms. 
    This paper will talk about parallelizing DSP hardware, and selected demonstrations of how software DSP algorithms can be parallelized. The mathematics and derivations of the DSP algorithms discussed, while critical to the study of DSP overall, will only be explained in brief as the focus of this paper is how these algorithms can be parallelized and what kind of efficiency increases are gained from parallelizing them.

What is Digital Signal Processing?
---------
    Since the targeted audience of this paper is software engineers and computer programmers as opposed to electrical engineers, what digital signal processing is and some of its applications will be discussed before diving into its parallelization. As mentioned in the abstract, digital signal processing at its most basic form is taking a stream of data, modifying it in some way, and outputting the modified stream.
    But what exactly is a signal? A signal in theoretical terms is a function which conveys information about a system. Signals exist all around us in nature. Commonly known signals are motion, sound, and images, however more esoteric signals would be biological membrane potentials or medical signals. This paper will use audio signals as a reference point since they are the easiest to conceptualize according to the author.
    A digital signal processor takes a digitized signal and performs various mathematical operations on the signal to modify it in some way. Signals can be digitized using an "ADC unit", an analog to digital converting unit. Output of a DSP-processed signal is done via a "DAC unit", a digital to analog converting unit.

Why parallelize DSP?
---------
    At its heart, DSP is essentially mathematical operations, which makes it an ideal candidate to think about how many DSP operations can be parallelized. Many common DSP operations are suited for task partitioning so they are relatively easy to parallelize in both hardware and software. A system running DSP operations in parallel can do so with a reduced clock speed, or run more DSP operations at the same clock speed as it would sequentially, resulting in increased data throughput. These days, parallel programming paradigms have been well established so it is much easier to experiment with ways to parallelize common DSP operations, which will be discussed in this paper.
    
    In addition to performance, different signal processing effects can be acheived whether multiple DSPs are done in series or in parallel. While the focus of the paper will be on the performance benefits of using parallel processing, a discussion about parallel processing and DSP cannot happen without talking about the effects of arranging multiple DSP units in different ways. 

Using DSP Hardware in Parallel
---------
    
Generating Signals
---------
    Let's start with something fundamental, generating some signals. After all, how are we going to process any signals without having some signals to work with in the first place?

    
Making a WAVE file Spectrum Analyzer and making it Realtime with Parallel Processing
---------
    If we want to analyze signals, we can use an oscilloscope and a spectrum analyzer. This demonstration is done in software although similar principles could be applied in hardware. An oscillosocope shows the waveform data of a signal with respect to time. A spectrum analyzer shows the data with respect to frequency, rather than time, using the infamous Fourier Transform. The Fourier Transform and its discrete friend the Fast Fourier Transform will be discussed in detail in the next section (in addition to parallel approaches to computing it) but for now, just know that it takes signal data represented in the time domain and transforms it into the frequency domain. That is, using a spectrum analyzer, the magnitudes of an input signal at each frequency can be viewed and analyzed.
    
    What if we want to analyze an audio signal stored in a wave file using a computer? One approach is to simply run the entire wave file data through an FFT algorithm and output the result.
    
            ### read the wav data
            sample_rate, data = wavfile.read(wavename)
            bit = DTYPES[str(data.dtype)] # get the data type
            data = data / (2. ** bit) # normalize the data
            data_len = data.shape[0] # get the total data points and number of channels
            
            ### plot the time domain
            time_axis = np.arange(0, data_len, 1) / sample_rate  # scale time pointsto seconds
            plt.subplot(2, 1, 1)
            plt.plot(time_axis, data, color='b')
            plt.xlabel("Time (sec)")
            plt.ylabel("Amplitude")

            ### plot the frequency domain (fourier transform)
            N = data_len
            FFT = fft_func(data) # calculate the fft with the specified function
            num_unique_points = int(np.ceil((N+1)/2.0))
            FFT = np.abs(FFT[0:num_unique_points]) # truncate the FFT to the region of the data points
            FFT = (FFT/float(N)) ** 2 # normalize the FFT

            # nyquist fix, see https://web.archive.org/web/20120615002031/http://www.mathworks.com/support/tech-notes/1700/1702.html
            if N % 2 != 0: # odd amount of FFT points
                FFT[1:len(FFT)] = FFT[1:len(FFT)] * 2
            else: # even amount of FFT points 
                FFT[1:len(FFT) - 1] = FFT[1:len(FFT) - 1] * 2
                
            << pepsiman_all.png >>    
                
        Figure: Reading a WAVE file and plotting the data onto a graph. 
        
    However, for many applications a more "real time" result is desired. That is, we would like to look at the current state of the signal while it is being outputted. For example, it is quite useful to look at the state of a signal before any signal processing is done to it, in addition to looking at the result after it is processed. With audio processing, seeing what a wave looks like "right now" rather than over its entire duration is often leveraged for making processing decisions. In order to accomplish this, we must change our strategy for analysis.
    
    Before talking about how parallel processing is utilized, it is vital to discuss the sequential flow for accomplishing this task.
    
    - make diagrams for program flows
    - actually discuss the problems
    
    
Parallelizing the Fast Fourier Transform
---------


The Butterworth Filters: Band Pass and Band Stop
----------


Conclusion
----------